{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Title: On the Impact of Events on Traffic Flow\n",
    "\n",
    "**Team Members:** Enrique Sanchez, Parker Addison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Question and Importance:\n",
    "\n",
    "> *How does the context in which an event is held affect the traffic conditions surrounding the event?*\n",
    "\n",
    "The only difference between the question addressed on our project proposal and that which is above is that we have generalized the question to include all events. These events could now be major, minor, festivals, sporting events, etc.\n",
    "\n",
    "The aim of our project was to explore the effect of events on nearby traffic conditions. We specifically focused on the effects of an event’s time, location, and the number of attendees. Although this does not take into consideration other important attributes such as attendee demographics, we were eager to explore the predictive power of these attributes. Generally, these three features are easily accessible so being able to predict traffic congestion solely on them would be tremendously useful.\n",
    "\n",
    "Answering the question posed above would be valuable for communities where events are held frequently. Large events (e.g. Comic Con) can be a huge burden on locals due to its upbringing of traffic. Being able to predict the traffic conditions and plan ahead for such conditions may save people time and keep busy cities moving. Let’s also be honest with ourselves, who wants to deal with pesky traffic?!\n",
    "\n",
    "From a business case perspective, event planners would have a field day having access to this tool.  A planner for an event with an already-established venue (fixed location) can utilize this tool to decide upon an event schedule (day of week and time of day begin/end) that allows attendees to sit in minimal traffic.  While a planner for a brand new event, or an event that seeks a new location, can use traffic predictions to get a sense of where people are coming from, and can choose a venue that minimizes traffic as well as a venue that satisfies other conditions.  For example, a certain location may lead to an increased traffic flow through a high crime part of the surrounding city.  It is unlikely that the event planners want their attendees developing a poor reputation for their city, so they can choose a different venue that routes traffic in another way. \n",
    "\n",
    "Of course, this is also handy for the city itself. Being aware of the impact that major events can bring to the city can help in developing regulations that minimize the impediment of events on traffic conditions. However, some major events may be in the best interests of the city in terms of the economic gain it can bring. In such cases, using this tool allows cities to effectively and efficiently prepare for the increased traffic that will be making its way through its city. This can come in the form of better traffic management, greater access to public transportation in the area, or the creation of more roads.\n",
    "\n",
    "It is also easy to imagine people being deterred from moving to a city that has a poor traffic reputation. If a solution to minimize/better manage unexpected traffic congestion is devised, it may help in developing a better reputation for the city and motivate more people to move there which can subsequently have a positive economic impact on the city. Of course, solving the event traffic problem is not the solution to solve the overarching traffic problem. However, it may be a critical step to slowly solve the problem that affects millions (or billions) of people.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Background & Literature\n",
    "\n",
    "1. “Special Event Management.” Texas A&M Transportation Institute\n",
    "https://mobility.tamu.edu/mip/strategies-pdfs/traffic-management/technical-summary/Special-Event-Management-4-Pg.pdf\n",
    "\n",
    "This article confirms many of the effects that special events can have on traffic congestion, as was mentioned before, and what can be done to minimize it. Rather than offering a method of predicting traffic congestion, it instead offers solutions to alleviate it. We would hope that these solutions would be used in conjunction with our congestion predictions to effectively determine the scale organizers need to take to implement them.\n",
    "\n",
    "2. Kwoczek, Simon, et al. “Predicting Traffic Congestion in Presence of Planned Special Events.” Journal of Visual Languages & Computing, vol. 25, no. 6, 2014, pp. 357–364.\n",
    "https://ksiresearchorg.ipage.com/seke/dms14paper/paper17.pdf\n",
    "\n",
    "This article aligns more with our implementation goals. However, instead of focusing on predicting incoming traffic to the event, it aims to predict outgoing traffic (after the event has ended) which they refer to as second wave traffic. They used many different algorithms such as KNN which were trained on historical traffic data from past events. Implementation details were not explicitly specified so we are uncertain of how to improve their methodology. Their results  are claimed to be up to 35% better than state of the art solutions. Ultimately, we intend on doing something similar but we are of course dealing with incoming traffic.\n",
    "\n",
    "3. Humphreys, Brad R., and Hyunwoong Pyun. “Professional Sporting Events and Traffic: Evidence from US Cities.” SSRN Electronic Journal, 2017, doi:10.2139/ssrn.2940762.\n",
    "http://busecon.wvu.edu/phd_economics/pdf/17-05.pdf\n",
    "\n",
    "The article reflects on the scarcity of research on the topic of events and local traffic conditions. In an effort to uncover some useful information, they explore the relationship between local traffic and Major League Baseball games. It found that for each additional 1,000 fans in attendance to an MLB games, there was a 1.749 increase in the average daily miles traveled. This amounts to a 6.9% increase in total annual vehicle miles driven in a typical city with annual MLB events. Overall, this would constitute a 2% increase in traffic congestion as a result of MLB sporting events.\n",
    "\n",
    "4. Zagidullin, Ramil. “Model of Road Traffic Management in the City during Major Sporting Events.” Transportation Research Procedia, vol. 20, 2017, pp. 709–716., doi:10.1016/j.trpro.2017.01.115.\n",
    "https://www.sciencedirect.com/science/article/pii/S2352146517301151\n",
    "\n",
    "The article explores the methods of road traffic management for sporting events. In doing so a mathematical model is built that reveals the root causes of increased travel time around sporting events. These causes include: background road traffic, public transport, and transport for major sporting events. \n",
    "\n",
    "---\n",
    "\n",
    "Overall, it was quite difficult to find references for the topic we worked on. Even the references that we did manage to find acknowledged the lack of information on the topic. Unfortunately, we were unable to get a hold of historical traffic data so we could not follow some methodologies highlighted above (reference 2). We did however get a better sense of what the factors that cause traffic congestion around events were. This helped us narrow down the features we used to predict traffic congestion. These features include the number of vehicles that came into the area, the proximity to highways, and the navigability of the area under normal conditions. As will be seen, we gathered this information from various data sources and using some geospatial tools such as geoenrichment and service areas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Libraries Used\n",
    "\n",
    "We didn’t know which packages we would use in our proposal, though we did hypothesize that we would use `arcgis.network`, which is still the case even though parts of our project changed considerably.\n",
    "\n",
    "**`arcgis.geocoding`**  \n",
    "Used to add geometric locations to events in unseen locations which were missing latitude/longitude.\n",
    "\n",
    "**`arcgis.features.manage_data`**  \n",
    "Used to dissolve the highways into a single feature to allow for distances to be computed between events and highways, and used to clip the layer to our study extent in order to speed up calculations.\n",
    "\n",
    "**`arcgis.geometry`**  \n",
    "Used to calculate the Euclidean distance between an event’s location and the nearest highway, and to create geometry objects from service area polygons.\n",
    "\n",
    "**`arcgis.geoenrichment`**  \n",
    "Used to calculate the number of automobiles owned in a location’s baseline service area.\n",
    "\n",
    "**`arcgis.network`**  \n",
    "Used to calculate service areas around an event’s location (both baseline and historical).\n",
    "\n",
    "**`pandas`, `datetime`, etc**  \n",
    "General packages used primarily to clean our data, query our data, or to add further logic to certain operations (such as creating service areas for a specific date and time).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Sources\n",
    "\n",
    "---\n",
    "**Title**: Special Events\n",
    "\n",
    "**URL**: https://data.sandiego.gov/datasets/special-events/\n",
    "\n",
    "**Number of records**: 2840\n",
    "\n",
    "**Description**: Dataset provided by DataSD containing details on all San Diego events since May 2016 that required a Special Events Permit.  Includes: Event name, Event Type, Event Url, Location (both description of address and lat/lon), Start date and time, End date and time, and Expected number of attendees and participants.\n",
    "\n",
    "---\n",
    "\n",
    "**Title**: California State Highways\n",
    "\n",
    "**URL**: https://ucsdonline.maps.arcgis.com/home/item.html?id=22cd676ed1f74a7290f64dd1dc9b8363\n",
    "https://services1.arcgis.com/8CpMUd3fdw6aXef7/arcgis/rest/services/California_State_Highway/FeatureServer/0\n",
    "\n",
    "**Number of records**: 1370\n",
    "\n",
    "**Description**: An official feature layer representing all highway routes in California.  Provided by Caltrans for planning purposes, and validated with the Postmile Validation Wizard, last updated October 2017.\n",
    "\n",
    "---\n",
    "\n",
    "**Unobtained**  \n",
    "**Title**: HERE Historical Traffic Data\n",
    "\n",
    "**URL**: https://www.here.com/products/traffic-solutions/road-traffic-analytics\n",
    "\n",
    "**Description**: Access to HERE’s historical traffic data would have allowed us to look at traffic flow (summarized by a single statistic such as average speed or throughput rate) for each street segment.  We were unable to obtain this dataset after reaching out to HERE, so we modified our project to utilize service areas as opposed to manually examining street segments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter password: ········\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "import arcgis\n",
    "import arcgis.network as network\n",
    "from arcgis.features import Feature, FeatureSet\n",
    "from arcgis.geoenrichment import *\n",
    "from arcgis.features.manage_data import dissolve_boundaries\n",
    "from arcgis.geometry import distance\n",
    "from arcgis.geocoding import Geocoder, get_geocoders, geocode\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "gis = GIS(username=\"pgaddiso_UCSDOnline8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_subtitle</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_desc</th>\n",
       "      <th>event_loc</th>\n",
       "      <th>event_start</th>\n",
       "      <th>event_end</th>\n",
       "      <th>exp_attendance</th>\n",
       "      <th>exp_participants</th>\n",
       "      <th>event_host</th>\n",
       "      <th>event_url</th>\n",
       "      <th>event_address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pacific Beach Tuesday Farmers' Market</td>\n",
       "      <td>51870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FARMERS</td>\n",
       "      <td>This farmer's market offers locally grown vege...</td>\n",
       "      <td>Bayard Street between Grand and Garnet Avenues</td>\n",
       "      <td>2019-12-31 14:00:00</td>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>800</td>\n",
       "      <td>60</td>\n",
       "      <td>Discover PB</td>\n",
       "      <td>www.pacificbeachmarket.com</td>\n",
       "      <td>Bayard Street &amp; Grand Avenue</td>\n",
       "      <td>32.799998</td>\n",
       "      <td>-117.254587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunday Artisan Market</td>\n",
       "      <td>52120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FARMERS</td>\n",
       "      <td>The Sunday Artisan Market provides space for l...</td>\n",
       "      <td>5th Avenue between Market Street and J Street</td>\n",
       "      <td>2019-12-29 10:00:00</td>\n",
       "      <td>2019-12-29 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>Gaslamp Quarter Association</td>\n",
       "      <td>www.gaslamp.org</td>\n",
       "      <td>5th Avenue &amp; Market Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Old Town Artisan's Market</td>\n",
       "      <td>51714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FARMERS</td>\n",
       "      <td>A weekend open air market offering an array of...</td>\n",
       "      <td>Harney Street between San Diego Avenue and Con...</td>\n",
       "      <td>2019-12-29 09:00:00</td>\n",
       "      <td>2019-12-29 16:30:00</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>Old Town San Diego Chamber of Commerce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harney Street &amp; San Diego Avenue</td>\n",
       "      <td>32.752779</td>\n",
       "      <td>-117.194902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             event_title  event_id  event_subtitle event_type  \\\n",
       "0  Pacific Beach Tuesday Farmers' Market     51870             NaN    FARMERS   \n",
       "1                  Sunday Artisan Market     52120             NaN    FARMERS   \n",
       "2              Old Town Artisan's Market     51714             NaN    FARMERS   \n",
       "\n",
       "                                          event_desc  \\\n",
       "0  This farmer's market offers locally grown vege...   \n",
       "1  The Sunday Artisan Market provides space for l...   \n",
       "2  A weekend open air market offering an array of...   \n",
       "\n",
       "                                           event_loc          event_start  \\\n",
       "0    Bayard Street between Grand and Garnet Avenues   2019-12-31 14:00:00   \n",
       "1      5th Avenue between Market Street and J Street  2019-12-29 10:00:00   \n",
       "2  Harney Street between San Diego Avenue and Con...  2019-12-29 09:00:00   \n",
       "\n",
       "             event_end exp_attendance exp_participants  \\\n",
       "0  2019-12-31 19:00:00            800               60   \n",
       "1  2019-12-29 15:00:00            NaN               30   \n",
       "2  2019-12-29 16:30:00            500              100   \n",
       "\n",
       "                                event_host                   event_url  \\\n",
       "0                              Discover PB  www.pacificbeachmarket.com   \n",
       "1             Gaslamp Quarter Association              www.gaslamp.org   \n",
       "2  Old Town San Diego Chamber of Commerce                          NaN   \n",
       "\n",
       "                      event_address   latitude   longitude  \n",
       "0      Bayard Street & Grand Avenue  32.799998 -117.254587  \n",
       "1       5th Avenue & Market Street         NaN         NaN  \n",
       "2  Harney Street & San Diego Avenue  32.752779 -117.194902  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the raw events data\n",
    "events = pd.read_csv('special_events_list_datasd.csv')\n",
    "events.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Cleaning\n",
    "\n",
    "**Special Events Dataset**:\n",
    "\n",
    "Due to the fact that the event data set was provided by DataSD, we anticipated it to require minimal cleaning. To our surprise, the data was actually very messy. There were problems with event start/end times, attendance for multi-day events, missing values, missing locations, “San Diego” events that are not within San Diego, and several other small errors. We believe that this comes as a consequence of bad data entry. We were also unable to access metadata for the data set so some assumptions needed to be made when cleaning. Overall, data cleaning required a lot of manipulation using pandas and some ArcGIS functions such as geocoding.\n",
    "\n",
    "A detailed description of the data cleaning for the events data set can be found in the cell below. \n",
    "\n",
    "**California State Highways**:\n",
    "\n",
    "*Note*: The dissolve_boundaries and extract_data was performed inside of the Map Viewer on ArcGIS Online.  As such, there is no code, but here are the steps we took:\n",
    "1. Load California State Highways.\n",
    "\n",
    "2. Make sure the highways are dissolved.  This layer already is, but layers that we used previously were not. Under the Analysis tab, run Dissolve Boundaries with default settings.\n",
    "\n",
    "3. Load in the dissolved layer.\n",
    "\n",
    "4. Under the Analysis tab, run Extract Data with Study Area set to a drawn box with proper min/max lat/long values, and check Clip Features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1845 entries, 0 to 1844\n",
      "Data columns (total 9 columns):\n",
      "title               1845 non-null object\n",
      "id                  1845 non-null int64\n",
      "type                1845 non-null object\n",
      "date                1845 non-null object\n",
      "start               1845 non-null object\n",
      "end                 1845 non-null object\n",
      "total_attendance    1845 non-null int64\n",
      "latitude            1845 non-null object\n",
      "longitude           1845 non-null object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 129.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>total_attendance</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pacific beach tuesday farmers market</td>\n",
       "      <td>51870</td>\n",
       "      <td>farmers</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>860</td>\n",
       "      <td>32.8</td>\n",
       "      <td>-117.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>old town artisans market</td>\n",
       "      <td>51714</td>\n",
       "      <td>farmers</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>600</td>\n",
       "      <td>32.7528</td>\n",
       "      <td>-117.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019 hillcrest farmers market (sundays)</td>\n",
       "      <td>52070</td>\n",
       "      <td>farmers</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>4400</td>\n",
       "      <td>32.7485</td>\n",
       "      <td>-117.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old town artisans market</td>\n",
       "      <td>51713</td>\n",
       "      <td>farmers</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>600</td>\n",
       "      <td>32.7528</td>\n",
       "      <td>-117.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city heights farmers market (every saturday)</td>\n",
       "      <td>51818</td>\n",
       "      <td>farmers</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>600</td>\n",
       "      <td>32.7478</td>\n",
       "      <td>-117.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title     id     type        date  \\\n",
       "0          pacific beach tuesday farmers market  51870  farmers  2019-12-31   \n",
       "1                      old town artisans market  51714  farmers  2019-12-29   \n",
       "2       2019 hillcrest farmers market (sundays)  52070  farmers  2019-12-29   \n",
       "3                      old town artisans market  51713  farmers  2019-12-28   \n",
       "4  city heights farmers market (every saturday)  51818  farmers  2019-12-28   \n",
       "\n",
       "      start       end  total_attendance latitude longitude  \n",
       "0  14:00:00  19:00:00               860     32.8  -117.255  \n",
       "1  09:00:00  16:30:00               600  32.7528  -117.195  \n",
       "2  09:00:00  14:00:00              4400  32.7485   -117.15  \n",
       "3  09:00:00  16:30:00               600  32.7528  -117.195  \n",
       "4  09:00:00  13:00:00               600  32.7478    -117.1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! This does not need to be run multiple times.  The cleaned events feature layer is\n",
    "#  published on ArcGIS Online -- just load it in that way\n",
    "\n",
    "run = False\n",
    "if run:\n",
    "\n",
    "    # ---------------------------- PART 1: Basic Cleaning/Setup ----------------------------\n",
    "\n",
    "    # Converting start and end times to datetime and creating year column\n",
    "    events['event_start'] = pd.to_datetime(events['event_start'])\n",
    "    events['event_end'] = pd.to_datetime(events['event_end'])\n",
    "    events['year'] = events['event_start'].dt.year\n",
    "\n",
    "    # Filling in null attendancez (helpful for future cleaning)\n",
    "    events['exp_attendance'] = events['exp_attendance'].fillna('')\n",
    "    events['exp_participants'] = events['exp_participants'].fillna('')\n",
    "\n",
    "    # We also have columns where text is present. We want to avoid any potential entry\n",
    "    # errors (unwanted spaces, capitalization, etc) so we will clean these columns.\n",
    "    def clean_text(text):\n",
    "        if pd.isnull(text):\n",
    "            return np.nan\n",
    "        no_marks = text.replace(\"'\", \"\").replace(\",\", \"\")\n",
    "        lower_whitespace = no_marks.lower().strip()\n",
    "\n",
    "        return lower_whitespace\n",
    "\n",
    "    text_cols = ['event_title', 'event_type', 'event_loc', 'event_host', 'event_address']\n",
    "    for col in text_cols:\n",
    "        events[col] = events[col].apply(clean_text)\n",
    "\n",
    "\n",
    "    # ----------------------------- PART 2: Start/End Time -----------------------------\n",
    "\n",
    "    # Interestingly, some events ended before they started giving us negative time deltas...\n",
    "    # This seems to arise from false representations of afternoon/morning times. For example, \n",
    "    # Old Town's Artisan Market begins at 9am and ends at 4:30pm yet we get some instances of \n",
    "    # ending times of 16:30:00 (correct) and 04:30:00. 12 hours off! They are not always 12\n",
    "    # hours off however. Those that end at midnight or 1am are represented as 00:00:00 or \n",
    "    # 01:00:00 in the same day that the event started! In such cases we must add 24 hours.\n",
    "\n",
    "    # Filter data set to those that have a start and end in the same day\n",
    "    same_day = events[events['event_start'].dt.day == events['event_end'].dt.day]\n",
    "\n",
    "    # Filter further to those events that end before they start\n",
    "    error = same_day[same_day['event_end'] < same_day['event_start']]\n",
    "\n",
    "    # Filtering to rows that will have time errors\n",
    "    day_error = error[error['event_end'].dt.hour.isin([0, 1])]\n",
    "    twelve_error = error[~error['event_end'].dt.hour.isin([0, 1])]\n",
    "\n",
    "    # Adding appropriate amount of time\n",
    "    day_error['event_end'] = day_error['event_end'] + pd.Timedelta(days=1)\n",
    "    twelve_error['event_end'] = twelve_error['event_end'] + pd.Timedelta(hours=12)\n",
    "\n",
    "    # Fixing time errors\n",
    "    events.loc[day_error.index, 'event_end'] = day_error['event_end']\n",
    "    events.loc[twelve_error.index, 'event_end'] = twelve_error['event_end']\n",
    "\n",
    "    # We also have an event that is 20 days long without a break between days. After\n",
    "    # doing some research online, this is in reality a single day event. Let's fix\n",
    "    # this single event.\n",
    "    event_start = pd.to_datetime('2019-04-27 18:00:00')\n",
    "    event_end = pd.to_datetime('2019-04-27 23:00:00')\n",
    "\n",
    "    botany_bash = events[events['event_title'] == 'san diego natural history museum botany bash']\n",
    "    events.loc[botany_bash.index, 'event_end'] = event_end\n",
    "    events.loc[botany_bash.index, 'event_start'] = event_start\n",
    "\n",
    "\n",
    "    # ------------------------------- PART 3: Attendance -------------------------------\n",
    "\n",
    "    # Since attendance has a huge effect on the traffic impact of an event we must ensure\n",
    "    # that the attendance is as accurate as possible. We have two problems however:\n",
    "    #\n",
    "    # 1. Every observation that has '(xx-day event)' (a multi day event) in the event title \n",
    "    #    has an expected attendance equal to that of the expected attendance of the entire event! Note\n",
    "    #    that this appears to affect the 'festival', 'athletic', and 'concert' events.\n",
    "    #    There also exists multi day events that do not specify the length of the event in the title\n",
    "    #    and simply have a 'X,XXX/day' in the attendance columns. \n",
    "    # 2. Nearly 10% of the data is missing attendance\n",
    "\n",
    "    # Let's begin by fixing the multi day event problem.\n",
    "\n",
    "    # Extracting affected rows\n",
    "    affected_events = ['festival', 'athletic', 'concert']\n",
    "    cols = ['event_title', 'exp_attendance', 'exp_participants', 'event_start', 'event_end', 'year']\n",
    "    attendance = events[events['event_type'].isin(affected_events)][cols]\n",
    "\n",
    "    # Only events events that happen more than once in a year can be affected - 655 observations\n",
    "    event_counts = attendance.groupby(['event_title', 'year']).size()\n",
    "    dup_events = event_counts[event_counts > 1].reset_index().drop(0, axis=1)\n",
    "    dup_events_data = events.merge(dup_events, on=['event_title', 'year'], how='inner', right_index=True)\n",
    "\n",
    "    # The longest multi day event spans 41 days, we can exlude events that have larger extents \n",
    "    multi_cut = pd.Timedelta(days=41)\n",
    "    ind_events = dup_events_data.groupby(['event_title', 'year'])\n",
    "\n",
    "    event_duration = ind_events.apply(lambda x: x['event_end'].max() - x['event_start'].min())\n",
    "    multiday_events = event_duration[event_duration < multi_cut].reset_index().drop(0, axis=1)\n",
    "    multiday_events_data = dup_events_data.merge(multiday_events, on=['event_title', 'year'], how='inner', right_index=True)\n",
    "\n",
    "    # We have now determined the potential multi day events (415 obervations), we can now assess\n",
    "    # which events have errors in its attendance... Unfortunately, after deeply analyzing the\n",
    "    # data, there seems to be no pattern to accurately determine the events with errors. Only\n",
    "    # events we are sure have accurate attendances are those with'X,XXX/day' representations. \n",
    "    # To prevent innacuracies in our future predictions, we will drop the other multi-day events.\n",
    "\n",
    "    # We want to remove events with no 'X,XXX/day' representation\n",
    "    potential_errors = multiday_events_data[~multiday_events_data['exp_attendance'].str.contains('/day')].index\n",
    "    events = events.drop(potential_errors, axis=0)\n",
    "\n",
    "    # Now we need to deal with events with missing attendances. There is very little we can do\n",
    "    # about missing attendance. If we look at events with missing attendance, nearly half come\n",
    "    # from 'daily food trucks' which we don't really consider a true event. We have chosen to\n",
    "    # not risk bad imputations and simply drop these events. GIGO!\n",
    "    events = events[(events['exp_attendance'] != '') & (events['exp_participants'] != '')]\n",
    "\n",
    "    # Let's also clean the attendance columns so that they are actual numbers!\n",
    "    def clean_attendance(event):\n",
    "        if event == '':\n",
    "            return np.nan\n",
    "\n",
    "        return int(event.replace('/day', '').replace(',', ''))\n",
    "\n",
    "    events['exp_attendance'] = events['exp_attendance'].apply(clean_attendance)\n",
    "    events['exp_participants'] = events['exp_participants'].apply(clean_attendance)\n",
    "\n",
    "\n",
    "    # ----------------------------- PART 4: Event Locations -----------------------------\n",
    "\n",
    "    # Since we are focused on determining the traffic impact of an event on surrounding areas,\n",
    "    # it is critical that we know where these events are located. It may be tempting to \n",
    "    # to go ahead and geocode all missing locations but some events share the same location \n",
    "    # (as represented by the 'event_address' variable) so we can replace missing locations\n",
    "    # with locations of events that occurred at the same location. We see some very slight \n",
    "    # variations in coordinates for the same same location at times but they still seem\n",
    "    # like fair estimates.\n",
    "\n",
    "    # Let's begin by creating a column that holds both the lat and lon for each event in a tuple.\n",
    "    events['location'] = events.apply(lambda x: (x['latitude'], x['longitude']), axis=1)\n",
    "\n",
    "    # Now we can create a dictionary for event addresses and their corresponding coordinates\n",
    "    with_location = events.dropna(subset=['latitude', 'longitude'])\n",
    "    location_dict = with_location.groupby('event_address')['location'].unique().apply(lambda x: x[0]).to_dict()\n",
    "\n",
    "    # Let's now replace events with missing locations with this dictionary\n",
    "    missing_locations = events[(events['latitude'].isnull()) | (events['longitude'].isnull())]\n",
    "    missing_locations['location'] = missing_locations['event_address'].apply(lambda x: location_dict.get(x))\n",
    "\n",
    "    # Now that we saved some locations, let's put it back into the dataframe\n",
    "    missing_locations['latitude'] = missing_locations['location'].apply(lambda x: np.nan if pd.isnull(x) else x[0])\n",
    "    missing_locations['longitude'] = missing_locations['location'].apply(lambda x: np.nan if pd.isnull(x) else x[1])\n",
    "\n",
    "    events['latitude'].loc[missing_locations.index] = missing_locations['latitude']\n",
    "    events['longitude'].loc[missing_locations.index] = missing_locations['longitude']\n",
    "\n",
    "    # We still have some missing locations. We will fill these in using geocoding!\n",
    "    # There are two columns that indicate location aside from lat and lon: event_loc & event_address.\n",
    "    # event_loc includes a brief description of the location which may be tricky to geocode. \n",
    "    # event_address on the other hand, gives us the intersection at which an event happens \n",
    "    # (e.g. 5th Avenue & Market Street). Thankfully, intersections can be geocoded!\n",
    "\n",
    "    # Finding locations that are still missing\n",
    "    further_missing = events[(events['latitude'].isnull()) | (events['longitude'].isnull())]\n",
    "\n",
    "    # Getting the unique event addresses so we don't geocode the same address (only 23 locations!)\n",
    "    unique_addresses = further_missing['event_address'].unique()\n",
    "\n",
    "    # Geocode!\n",
    "    for address in unique_addresses:\n",
    "        if pd.isnull(address):\n",
    "            continue\n",
    "\n",
    "        # Extracting coordinates\n",
    "        geocoded = geocode(address + ', San Diego')\n",
    "        longitude = geocoded[0]['attributes']['X']\n",
    "        latitude = geocoded[0]['attributes']['Y']\n",
    "\n",
    "        # Imputing\n",
    "        further_missing['latitude'].loc[further_missing['event_address'] == address] = latitude\n",
    "        further_missing['longitude'].loc[further_missing['event_address'] == address] = longitude\n",
    "\n",
    "    # Now that we geocoded, we only have 20 locations without an address! We will simply drop these.\n",
    "    # We can also update our events data set\n",
    "    events['latitude'].loc[further_missing.index] = further_missing['latitude']\n",
    "    events['longitude'].loc[further_missing.index] = further_missing['longitude']\n",
    "    events = events.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "\n",
    "    # ----------------------------- PART 5: Finishing Touches -----------------------------\n",
    "\n",
    "    # Now that the most important features area clean, we can start dropping and setting our\n",
    "    # data frame for some work!\n",
    "\n",
    "    # We should remove any events that are outside of San Diego county.  There aren't too many\n",
    "    # cases of this, and there aren't any 'close-calls', so we can use rudimentary extents to\n",
    "    # figure out what to drop.\n",
    "    sd_extent = {\"lonmin\": -117.6, \"lonmax\": -116, \"latmin\": 32.5, \"latmax\": 33.5}\n",
    "    events = events[\n",
    "          (events.latitude >= sd_extent[\"latmin\"])\n",
    "        & (events.latitude <= sd_extent[\"latmax\"])\n",
    "        & (events.longitude >= sd_extent[\"lonmin\"])\n",
    "        & (events.longitude <= sd_extent[\"lonmax\"])\n",
    "    ]\n",
    "\n",
    "    # Creating a variable for the total expected attendance\n",
    "    events['total_attendance'] = events['exp_attendance'] + events['exp_participants']\n",
    "\n",
    "    # Creating clearer date/time columns\n",
    "    events['event_date'] = events['event_start'].dt.date\n",
    "    events['event_start'] = events['event_start'].dt.time\n",
    "    events['event_end'] = events['event_end'].dt.time\n",
    "\n",
    "    # Keeping only necessary columns\n",
    "    cols = ['event_title', 'event_id', 'event_type', 'event_date', 'event_start',\n",
    "            'event_end', 'total_attendance', 'latitude', 'longitude']\n",
    "\n",
    "    events = events[cols].reset_index(drop=True)\n",
    "\n",
    "    # Renaming columns\n",
    "    events.columns = pd.Series(events.columns).apply(lambda x: x.replace('event_', ''))\n",
    "\n",
    "    # Let's now see the clean data!\n",
    "    display(events.info())\n",
    "    events.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3963a043dcd54d23a576c7c55d9fb37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-static-img-preview-c37f9396-8e6b-46d3-9087-cb4c6b6e18c5\"><img src=\"\"></img></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converting data to sdf and creating feature layer from it for future use\n",
    "# Note creating copy since you can't create a feature layer from an sdf with datetime columns\n",
    "\n",
    "# events_sdf = pd.DataFrame.spatial.from_xy(events, x_column = 'longitude', y_column='latitude')\n",
    "# events_sdf = events_sdf.astype({'date':'str','start':'str','end':'str'})\n",
    "\n",
    "# events_fl = events_sdf.spatial.to_featurelayer(title='San Diego Event Locations', tags='events').layers[0]\n",
    "#\n",
    "# NOTE: This was already run, we can just read it in from arcgis.\n",
    "#       This feature layer is a cleaned version of our events dataset.\n",
    "events_fl = gis.content.get(\"eda42c7fb00f4996a00b769ed74843c6\").layers[0]\n",
    "\n",
    "# We will use 3857 for this project\n",
    "events_sdf = events_fl.query(out_sr='3857').sdf\n",
    "\n",
    "# Plotting the events\n",
    "map1 = gis.map('San Diego')\n",
    "map1.add_layer(events_fl)\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Descriptive Statistics\n",
    "\n",
    "Looking at our events dataset, we see some imbalances that could potentially affect the accuracy of our model. (That is, if we were able to train a model!)  Location-wise, we see that most of the events in our dataset are clustered around downtown San Diego.  Likewise, the majority of events are farmers markets.  When training a model, it would be important to address these class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364752ba44d14f2280f8e4afa4ae9c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-static-img-preview-19db1d7f-a059-4292-b521-b11f31a81326\"><img src=\"\"></img></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = gis.map('San Diego')\n",
    "m.add_layer(events_fl, {\"renderer\": \"HeatmapRenderer\", \"opacity\":0.5})\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "events_sdf.groupby(\"type\").FID.count().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we examine event type by location, we notice some interesting things:\n",
    "- There are a cluster of athletic events that happen around mission bay.\n",
    "- Other than that, most events are evenly distributed, especially festivals and athletic events\n",
    "- Though farmers markets have have the vast majority of entries in our dataset, most of these farmers markets occur in the same spot every week, so there aren’t actually many locations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62ff39006f747f9bbcac9388ca2e316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'), legend=True, zoom=11.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-static-img-preview-46544886-7788-4008-86a6-babac282e24e\"><img src=\"\"></img></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some class imbalances/location imbalances.\n",
    "#\n",
    "# Let's see if the event types are evenly spread across locations though.\n",
    "m2 = gis.map(\"San Diego\", zoomlevel=11)\n",
    "events_sdf.spatial.plot(\n",
    "    map_widget=m2,\n",
    "    renderer_type='u',\n",
    "    col=\"type\"\n",
    ")\n",
    "m2.legend = True\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis\n",
    "\n",
    "This plan has changed significantly from our proposal due to a handful of reasons.  While we weren’t able to conduct the model training that our original proposal suggested, our final plan ended up being to create a pipeline that can be used to facilitate analysis if we were able to access detailed historical datasets!\n",
    "\n",
    "Plan of action:\n",
    "1. Read in and clean events data\n",
    "2. Read in and clean (dissolve and clip) highways layer\n",
    "3. For each event calculate/engineer features (additional X variables):\n",
    "    1. Calculate the area of the baseline service area.  This is how far away you can be while still being able to arrive at the event in 5 or less minutes.  The baseline service area is a typical service area, conditional on date, day, and time.  This is handled by ArcGIS by passing in a service area date 28 years in the future, but with the same date and time as the event—exact calendar date-day combinations repeat every 28 years.\n",
    "    2. For the baseline area, geoenrich the number of automobiles owned in the area.\n",
    "    3. Calculate the Attendee-Vehicle ratio, which is the number of expected attendees over the number of automobiles owned in the area.\n",
    "    4. Calculate the distance between the event and the nearest highway.\n",
    "4. For each event calculate studied variable (y variable):\n",
    "    1. Calculate the area of the historical, 'impacted' service area.  This is the same drive-to service area as before, but the date passed in is the datetime of the event.  We designed our function to call the correct code, however it will return baselines if the datetime is outside of 12 hours in the past!\n",
    "    2. Calculate the proportion change from baseline area to impacted area.  This is our y variable.\n",
    "5. Build a model; pass in X features (total attendance, event type, event time, service area size, number of vehicles, A-V ratio, and distance to highway) and predict the y variable (proportion change in service area).  We don’t have access to any true y variables, but this step is as simple as instantiating a sklearn model, creating a train-test split, and calling `.fit(X, y)`!\n",
    "6. Sit back and use the pipeline to run analysis on the impact of events on traffic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on a single event first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating service area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_area_url = gis.properties.helperServices.serviceArea.url\n",
    "sa_layer = network.ServiceAreaLayer(service_area_url, gis=gis)\n",
    "travel_modes = sa_layer.retrieve_travel_modes()\n",
    "car_mode = [t for t in travel_modes['supportedTravelModes'] if t['name'] == 'Driving Time'][0]\n",
    "\n",
    "sref_3857 = {'latestWkid': 3857, 'wkid': 102100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7564669.136686617"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = datetime(2000, 1, 1, 11).timestamp() * 1000\n",
    "\n",
    "# Event location\n",
    "event1 = events_sdf.loc[0]\n",
    "loc1 = str(event1['longitude']) + ', ' + str(event1['latitude'])\n",
    "\n",
    "# Compute the service area\n",
    "\n",
    "# sa_4326 = sa_layer.solve_service_area(facilities=event1, default_breaks=[5], travel_mode=car_mode,\n",
    "#                                       travel_direction='esriNATravelDirectionFromFacility',\n",
    "#                                       time_of_day=time, time_of_day_is_utc=False,\n",
    "#                                       out_sr={'latestWkid': 4326, 'wkid': 4326})\n",
    "    \n",
    "sa_3857 = sa_layer.solve_service_area(facilities=loc1, default_breaks=[5], travel_mode=car_mode,\n",
    "                                      travel_direction='esriNATravelDirectionToFacility',\n",
    "                                      time_of_day=time, time_of_day_is_utc=False,\n",
    "                                      out_sr=sref_3857)\n",
    "\n",
    "# Calculating service area Area\n",
    "service_area_area = sa_3857['saPolygons']['features'][0]['attributes']['Shape_Area']\n",
    "service_area_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3744b541f1042369e31e885603d2773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'), zoom=10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-static-img-preview-279a71c6-f907-4103-9937-2bf1820760ae\"><img src=\"\"></img></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Service Area\n",
    "service_area = arcgis.geometry.Geometry(sa_3857['saPolygons']['features'][0]['geometry'], spatialReference=sref_3857)\n",
    "map1 = gis.map(\"San Diego\", zoomlevel=10)\n",
    "map1.draw(service_area)\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriching with number of automobiles owned in service area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12905"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figuring out the number of vehicles in this area\n",
    "# Number of 1 vehicle owned: 'MP01002h_B'\n",
    "# Number of 2 vehicles owned: 'MP01003h_B'\n",
    "# Number of 3 or more vehicles owned: 'MP01004h_B'\n",
    "# Source: http://doc.arcgis.com/en/esri-demographics/data/data-browser.htm\n",
    "vehicles = enrich(study_areas=[service_area], data_collections=['AutomobilesAutomotiveProducts']) \n",
    "\n",
    "# Total number of vehicles in the service area\n",
    "num_vehicles = (vehicles.MP01002h_B + 2*vehicles.MP01003h_B + 3*vehicles.MP01004h_B)[0]\n",
    "num_vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating distance to nearest highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The dissolve_boundaries and extract_data was performed on the following layer\n",
    "#       inside of the Map Viewer on ArcGIS Online.  As such, there is no code, but here\n",
    "#       are the steps we took:\n",
    "# 1. Load California State Highways.\n",
    "#\n",
    "# 2. Make sure the highways are dissolved.  This layer already is, but layers that we\n",
    "#    used previously were not.\n",
    "#    Under the Analysis tab, run Dissolve Boundaries with default settings.\n",
    "#\n",
    "# 3. Load in the dissolved layer.\n",
    "#\n",
    "# 4. Under the Analysis tab, run Extract Data with Study Area set to a drawn box with\n",
    "#    proper min/max lat/long values, and check Clip Features.\n",
    "\n",
    "# ca_highways = gis.content.get(\"22cd676ed1f74a7290f64dd1dc9b8363\")\n",
    "\n",
    "highways = gis.content.get(\"5cdc4f0e9c47499aa67be8d6e0bf6091\")\n",
    "highways_fl = highways.layers[0]\n",
    "highways_sdf = highways_fl.query().sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3384.51232589273"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating distance to nearest highway\n",
    "distance_to_highway = distance(geometry1= events_sdf['SHAPE'].loc[0], \n",
    "                               geometry2=highways_sdf['SHAPE'].loc[0], \n",
    "                               spatial_ref=sref_3857, \n",
    "                               geodesic=True)['distance']\n",
    "\n",
    "distance_to_highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7bec4e490349f79913a48ade789943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'), zoom=10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-static-img-preview-aeba684d-77b0-457a-90e2-1a7d487043ef\"><img src=\"\"></img></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map of highways and event location\n",
    "map2 = gis.map('San Diego', zoomlevel=10)\n",
    "map2.add_layer(highways)\n",
    "events_sdf.loc[[0]].spatial.plot(map_widget=map2)\n",
    "map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: pacific beach tuesday farmers market\n",
      "Area of the service area: 7564669 meters-squared.\n",
      "Number of vehicles in service area: 12905.\n",
      "Distance to the nearest highway: 3384 meters.\n"
     ]
    }
   ],
   "source": [
    "# To sum it all up, these are the new features we generated\n",
    "\n",
    "print('Event: %s' % events_sdf['title'].loc[0])\n",
    "print('Area of the service area: %d meters-squared.' %service_area_area)\n",
    "print('Number of vehicles in service area: %d.' %num_vehicles)\n",
    "print('Distance to the nearest highway: %d meters.' %distance_to_highway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_service_area(event, baseline=True):\n",
    "    \"\"\"\n",
    "    Helper Function.\n",
    "    \n",
    "    Calculates the 5 minute service area for an event\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    date = event['date'].split('-')\n",
    "    \n",
    "    if baseline:\n",
    "        # Predicting far into the past/future will generate a service area on typical traffic speeds.\n",
    "        # Note that we want these baselines to be conditional on day and time.  We're not sure if Esri\n",
    "        # takes the date into account as well as the day of week, so we can use the fact that calendars\n",
    "        # will exactly repeat day-date combinations every 28 years (no matter if it's a leap year or not)\n",
    "        #\n",
    "        # Source:\n",
    "        # https://www.answers.com/Q/How_often_in_years_do_calendars_repeat_with_the_same_day-date_combinations\n",
    "        \n",
    "        date[0] = str(int(date[0]) + 28)\n",
    "        \n",
    "    # Make sure that the time is still the same as the event!\n",
    "    start_time = event['start'][:2]\n",
    "\n",
    "    time = datetime(int(date[0]), int(date[1]), int(date[2]), int(start_time)).timestamp() * 1000\n",
    "    location = str(event['longitude']) + ', ' + str(event['latitude'])\n",
    "    \n",
    "    service_area = sa_layer.solve_service_area(facilities=location, default_breaks=[5], travel_mode=car_mode,\n",
    "                                               travel_direction='esriNATravelDirectionToFacility',\n",
    "                                               time_of_day = time, time_of_day_is_utc=False,\n",
    "                                               out_sr={'latestWkid': 3857, 'wkid': 102100})\n",
    "    \n",
    "    # This can be easily changed to work with end_time and TravelDirectionFromFacility to measure\n",
    "    # traffic impact from people leaving the event!\n",
    "    \n",
    "    return service_area\n",
    "\n",
    "\n",
    "def area_service_area(service_area):\n",
    "    \"\"\"\n",
    "    Helper Function.\n",
    "    \n",
    "    Calculates the area of a service area in meters.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return service_area['saPolygons']['features'][0]['attributes']['Shape_Area']\n",
    "    \n",
    "    \n",
    "def num_vehicles(service_area):\n",
    "    \"\"\"\n",
    "    Helper Function.\n",
    "    \n",
    "    Calculates the number of vehicles in a service area\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    study_area = arcgis.geometry.Geometry(\n",
    "        service_area['saPolygons']['features'][0]['geometry'], spatialReference=sref_3857\n",
    "    )\n",
    "    vehicles = enrich(study_areas=[study_area], data_collections=['AutomobilesAutomotiveProducts']) \n",
    "    num_vehicles = (vehicles.MP01002h_B + 2*vehicles.MP01003h_B + 3*vehicles.MP01004h_B)[0]\n",
    "    \n",
    "    return num_vehicles\n",
    "\n",
    "\n",
    "def dist_to_highway(event):\n",
    "    \"\"\"\n",
    "    Helper Function.\n",
    "    \n",
    "    Calculates the distance of an event to the highway.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    distance_to_highway = distance(geometry1= event['SHAPE'], \n",
    "                               geometry2=highways_sdf['SHAPE'].loc[0], \n",
    "                               spatial_ref={'latestWkid': 3857, 'wkid': 102100}, \n",
    "                               geodesic=True)['distance']\n",
    "    \n",
    "    return distance_to_highway\n",
    "\n",
    "\n",
    "def generate_features(event):\n",
    "    \"\"\"\n",
    "    Generates the following features for a particular event:\n",
    "    \n",
    "    1. The area of the 5 minute service area\n",
    "    2. The number of veicles in a service area\n",
    "    3. The distance of the event to the nearest highway\n",
    "    \n",
    "    Outputs a dataframe of three columns containing these values.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    service_area = calc_service_area(event, baseline=True)\n",
    "    area = area_service_area(service_area)\n",
    "    vehicles = num_vehicles(service_area)\n",
    "    distance = dist_to_highway(event)\n",
    "    av_ratio = event[\"total_atte\"] / vehicles\n",
    "    \n",
    "    features = pd.DataFrame({'service_area':[area], 'num_vehicles':[vehicles], 'av_ratio':[av_ratio], 'dist_to_highway':[distance]})\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_area</th>\n",
       "      <th>num_vehicles</th>\n",
       "      <th>av_ratio</th>\n",
       "      <th>dist_to_highway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.995374e+06</td>\n",
       "      <td>14633</td>\n",
       "      <td>0.058771</td>\n",
       "      <td>3384.512326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   service_area  num_vehicles  av_ratio  dist_to_highway\n",
       "0  8.995374e+06         14633  0.058771      3384.512326"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing.\n",
    "#\n",
    "# NOTE: It is likely that these numbers will differ slightly from the example calculated above.\n",
    "#       The generalized procedure produces a baseline for the service area, which in turn affects\n",
    "#       the enriched number of vehicles, whereas the example above calculates a service area for\n",
    "#       a set date, day, and time that may not match the actual event.\n",
    "generate_features(events_sdf.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on all.\n",
    "#\n",
    "#! IMPORTANT: Please do not run this any more!  With all of these service area calculations\n",
    "#  this burns through credits like a fire in a pile of flammable stuff.\n",
    "\n",
    "run = False\n",
    "if run:\n",
    "\n",
    "    events_features = pd.DataFrame()\n",
    "\n",
    "    for index, event in events_sdf.iterrows():\n",
    "\n",
    "        events_features = events_features.append(generate_features(event), ignore_index=True)\n",
    "\n",
    "        \n",
    "    evsdf = events_sdf.merge(events_features, left_index=True, right_index=True)\n",
    "    ev = evsdf.dropna().astype({'date':'str','start':'str','end_':'str'})\n",
    "    \n",
    "    # to_featurelayer fails because there are less than 1000 entries.\n",
    "    # So, instead we just saved a csv.\n",
    "    ev.spatial.to_featurelayer(\"Events Features\", tags=\"features\")\n",
    "    evsdf.to_csv(\"events-features1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>date</th>\n",
       "      <th>end_</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>start</th>\n",
       "      <th>title</th>\n",
       "      <th>total_atte</th>\n",
       "      <th>type</th>\n",
       "      <th>service_area</th>\n",
       "      <th>num_vehicles</th>\n",
       "      <th>av_ratio</th>\n",
       "      <th>dist_to_highway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'x': -13042312.189404054, 'y': 3857633.435881...</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>49813</td>\n",
       "      <td>32.715738</td>\n",
       "      <td>-117.161084</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>curbside bites food truck markets - downtown l...</td>\n",
       "      <td>330</td>\n",
       "      <td>farmers</td>\n",
       "      <td>4.516798e+06</td>\n",
       "      <td>15931</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>684.266175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'x': -13042916.620843215, 'y': 3858589.669007...</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>50910</td>\n",
       "      <td>32.722965</td>\n",
       "      <td>-117.166514</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>little italys wednesday farmers market</td>\n",
       "      <td>1280</td>\n",
       "      <td>farmers</td>\n",
       "      <td>3.459450e+06</td>\n",
       "      <td>9725</td>\n",
       "      <td>0.131620</td>\n",
       "      <td>191.687997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{'x': -13052720.918015596, 'y': 3868787.072960...</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>51870</td>\n",
       "      <td>32.799998</td>\n",
       "      <td>-117.254587</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>pacific beach tuesday farmers market</td>\n",
       "      <td>860</td>\n",
       "      <td>farmers</td>\n",
       "      <td>8.995374e+06</td>\n",
       "      <td>14633</td>\n",
       "      <td>0.058771</td>\n",
       "      <td>3384.512326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FID                                              SHAPE        date  \\\n",
       "0    1  {'x': -13042312.189404054, 'y': 3857633.435881...  2018-08-08   \n",
       "1    2  {'x': -13042916.620843215, 'y': 3858589.669007...  2018-08-08   \n",
       "2    3  {'x': -13052720.918015596, 'y': 3868787.072960...  2019-12-31   \n",
       "\n",
       "       end_     id   latitude   longitude     start  \\\n",
       "0  14:00:00  49813  32.715738 -117.161084  11:00:00   \n",
       "1  13:00:00  50910  32.722965 -117.166514  09:00:00   \n",
       "2  19:00:00  51870  32.799998 -117.254587  14:00:00   \n",
       "\n",
       "                                               title  total_atte     type  \\\n",
       "0  curbside bites food truck markets - downtown l...         330  farmers   \n",
       "1             little italys wednesday farmers market        1280  farmers   \n",
       "2               pacific beach tuesday farmers market         860  farmers   \n",
       "\n",
       "   service_area  num_vehicles  av_ratio  dist_to_highway  \n",
       "0  4.516798e+06         15931  0.020714       684.266175  \n",
       "1  3.459450e+06          9725  0.131620       191.687997  \n",
       "2  8.995374e+06         14633  0.058771      3384.512326  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evsdf = pd.read_csv(\"events-features1.csv\", index_col=\"Unnamed: 0\")\n",
    "evsdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A \"real\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                                                32.8777\n",
       "longitude                                              -117.237\n",
       "date                                                 2019-06-06\n",
       "start                                                  18:30:00\n",
       "title                          dsc 170 final presentation party\n",
       "total_atte                                                 4000\n",
       "type                                                    exhibit\n",
       "SHAPE         {'x': -13050791.639920656, 'y': 3879075.417441...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsc170 = pd.DataFrame(columns=[\"latitude\", \"longitude\", \"date\", \"start\", \"title\", \"total_atte\", \"type\"],\n",
    "                     data=[[32.877651, -117.237256, \"2019-06-06\", \"18:30:00\", \"dsc 170 final presentation party\", 4000, \"exhibit\"]]\n",
    ")\n",
    "dsc170_sdf = pd.DataFrame.spatial.from_xy(dsc170, \"longitude\", \"latitude\", sr=4326)\n",
    "dsc170_sdf[\"SHAPE\"] = arcgis.geometry.project([dsc170.SHAPE[0]], in_sr=4326, out_sr=3857)\n",
    "dsc170_sdf.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_area</th>\n",
       "      <th>num_vehicles</th>\n",
       "      <th>av_ratio</th>\n",
       "      <th>dist_to_highway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.713553e+07</td>\n",
       "      <td>15473</td>\n",
       "      <td>0.258515</td>\n",
       "      <td>788.020208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   service_area  num_vehicles  av_ratio  dist_to_highway\n",
       "0  1.713553e+07         15473  0.258515       788.020208"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_features(dsc170_sdf.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_atte</th>\n",
       "      <th>type</th>\n",
       "      <th>service_area</th>\n",
       "      <th>num_vehicles</th>\n",
       "      <th>av_ratio</th>\n",
       "      <th>dist_to_highway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000</td>\n",
       "      <td>exhibit</td>\n",
       "      <td>1.713553e+07</td>\n",
       "      <td>15473</td>\n",
       "      <td>0.258515</td>\n",
       "      <td>788.020208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_atte     type  service_area  num_vehicles  av_ratio  dist_to_highway\n",
       "0        4000  exhibit  1.713553e+07         15473  0.258515       788.020208"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (\n",
    "    pd.concat([dsc170_sdf, generate_features(dsc170_sdf.loc[0])], axis=1)\n",
    "    [[\"total_atte\", \"type\", \"service_area\", \"num_vehicles\", \"av_ratio\", \"dist_to_highway\"]]\n",
    ")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12462563567923099"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (15_000_000 - X.service_area[0]) / X.service_area[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary & Results\n",
    "\n",
    "Although we were unable to make real event traffic impact predictions, we were successful in creating a framework that can be used to make such predictions if historical service area data were to become available in the future. The framework is generally easy to interpret and can be modified if alternate features prove to be more effective. Gathering more data for this framework is also relatively easy as event location, attendance, type, and time is readily accessible online.\n",
    "\n",
    "```\n",
    "X = generate_features([events])\n",
    "\n",
    "impacted_areas = area_service_area([\n",
    "    calc_service_area([events], baseline=False)\n",
    "])\n",
    "y = (impacted_areas - X.service_areas) / X.service_areas\n",
    "\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "We have had the opportunity to research and work on a topic that has very rarely been explored. This framework can be used to guide future work and help different parties assess the impact of events on nearby traffic conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Discussion\n",
    "\n",
    "1.\n",
    "\n",
    "The literature we found didn’t provide much of an opportunity to validate their work!  Instead, we ended up referencing some of the sources in order to better inform our decisions for the features that we ended up engineering.  One of the sources claims some statistics pertaining to MLB events and the consequential increases in typical miles driven to get to the event.  Perhaps with our framework in place, this could be an easy claim to examine.\n",
    "\n",
    "2.\n",
    "\n",
    "The features that we choose have a profound effect on the output and usefulness of our model/analysis.  Although we took plenty of time researching which features seemed most likely to have a measurable effect on traffic conditions, it is important to note that needing to rely on features potentially prevents future analysis from uncovering what is truly going on behind the scenes.\n",
    "\n",
    "On one hand, the use of engineered features allows models to have high accuracy on small amounts of data, and allows human domain experts to interpret and explain the importance of each feature, which can then directly be transitioned into actions—how do we change the values of those features?  We can just move the event to a different time, or add some more highway infrastructure, etc.  \n",
    "On the other hand, our original plan would have relied on a large amount of data, and allowed a model many iterations to uncover interrelations that may be yet unhypothesized!  For this plan, we would have fed in a ton of street-segment traffic conditions surrounding events, as well as some event-specific information only (as opposed to geographic information), and we’d let the model develop its own hidden features.  This would have been similar to Dmitry Kudinov’s example of training a neural net on billions of 'trips' to predict service area, and then observing that the neural net learned about concepts/relations involving highways, rush hour, and other traffic-related objects and events.  It would have been an interesting application of data analytics, because we would need to then take the model’s predictions and attempt to reverse engineer the relations created in the black box!\n",
    "\n",
    "Additionally, we chose to calculate 5 minute driving-time service areas, which could have just as easily been another number.  This was arbitrary, and we’re honestly not sure what kind of effects it would have on future analysis—perhaps it depends on how large the events are, since a very large event could cause traffic jams many miles away from the actual location!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion & Future Work\n",
    "\n",
    "We were not quite able to completely answer our initial research question. As has already been mentioned, we were unable to gain access to historical traffic data and could therefore not calculate the traffic impact of an event. If we were to gain access to such data, we can assess the predictive power of the features we generated or explore other possible features that could help determine traffic impact. \n",
    "\n",
    "Despite the drawbacks, we believe that we have created something useful that can be used for future development, not just in events, but other facets of society. For example, it could be used to assess the traffic impact of newly built infrastructure in a city such as business buildings or schools. In such cases, we can treat estimated daily human traffic as attendance and the hours of work or school as times. Really any area with a known location, daily attendance, and time can be treated as an event. \n",
    "\n",
    "Ultimately, many small parameters/arguments can be changed in the code above in order to facilitate the study of different areas. For example: the service areas can be calculated using DirectionFromFacility instead of DirectionTo, and the datetime passed in would use the end time of the event instead of the start time. Likewise, the service area could be any distance, whether that is driving, walking, or biking. It really depends on the user and what they hope to accomplish. This is why there isn’t necessarily a specific individual that this is targeted for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
